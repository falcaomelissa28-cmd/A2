import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import re
import unicodedata
from collections import Counter

# ----------------------------
# CONFIGURA√á√ÉO DO APP
# ----------------------------
st.set_page_config(page_title="Fashion Law Analyzer", page_icon="üëó", layout="centered")

st.title("üëó Fashion Law Analyzer")
st.subheader("An√°lise de Propriedade Intelectual e Contrafa√ß√£o na Moda")

# Palavras-chave principais
PALAVRAS_CHAVE = [
    'marca', 'registro', 'trademark', 'pirataria', 'contrafa√ß√£o',
    'imita√ß√£o', 'trade dress', 'design', 'autoral',
    'propriedade intelectual', 'uso indevido', 'direitos autorais'
]

# ----------------------------
# FUN√á√ïES AUXILIARES
# ----------------------------
def normalize_text(text):
    """Remove acentos, coloca min√∫sculas e normaliza espa√ßos."""
    if not isinstance(text, str):
        text = str(text)
    text = text.lower()
    text = unicodedata.normalize('NFKD', text)
    text = ''.join([c for c in text if not unicodedata.combining(c)])
    return re.sub(r'\s+', ' ', text).strip()

def tokenize(text):
    """Retorna as palavras (tokens) de um texto."""
    return re.findall(r'\w+', text)

def analisar_textos(df, palavras_chave):
    """Conta ocorr√™ncias de palavras e frases em cada documento."""
    textos_norm = df['Texto_Documento'].fillna('').apply(normalize_text)

    contagem_palavras = Counter()
    contagem_por_doc = {}

    frases = [p for p in palavras_chave if ' ' in p]
    simples = [p for p in palavras_chave if ' ' not in p]

    simples_norm = [normalize_text(p) for p in simples]
    frases_norm = [normalize_text(p) for p in frases]

    for idx, texto in textos_norm.items():
        total_termos_doc = 0

        for frase in frases_norm:
            num = texto.count(frase)
            if num > 0:
                contagem_palavras[frase] += num
                total_termos_doc += num

        tokens = tokenize(texto)
        token_counts = Counter(tokens)
        for palavra in simples_norm:
            num = token_counts.get(palavra, 0)
            if num > 0:
                contagem_palavras[palavra] += num
                total_termos_doc += num

        contagem_por_doc[df.loc[idx, 'ID']] = total_termos_doc

    return contagem_palavras, contagem_por_doc

# ----------------------------
# INTERFACE STREAMLIT
# ----------------------------
st.markdown("Envie um arquivo CSV contendo uma coluna **Texto_Documento** para an√°lise.")

uploaded_file = st.file_uploader("üìÅ Escolha o arquivo CSV", type=["csv"])

# Carrega CSV de exemplo se o usu√°rio n√£o enviar um
if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
else:
    st.info("Usando base de exemplo, pois nenhum arquivo foi enviado.")
    df = pd.DataFrame({
        'ID': [101, 102, 103, 104, 105],
        'Data': ['2025-01-10', '2025-02-15', '2025-03-20', '2025-04-01', '2025-05-05'],
        'Texto_Documento': [
            "A grande marca de luxo ingressou com a√ß√£o de contrafa√ß√£o pelo design n√£o autorizado do produto. A propriedade intelectual foi violada.",
            "Novo registro de marca para a cole√ß√£o sustent√°vel. A empresa protegeu sua marca e seu trade dress.",
            "Discuss√£o sobre a prote√ß√£o de direitos autorais em estampas de moda. A imita√ß√£o de tecidos √© uma preocupa√ß√£o.",
            "A pirataria de t√™nis continua sendo um desafio. Uso indevido de logo √© recorrente.",
            "Registro da nova cor como marca tridimensional. Fortalecimento da prote√ß√£o da marca."
        ]
    })

if st.button("üîç Analisar"):
    if 'Texto_Documento' not in df.columns:
        st.error("O arquivo deve conter uma coluna chamada 'Texto_Documento'.")
    else:
        contagem_palavras, contagem_por_doc = analisar_textos(df, PALAVRAS_CHAVE)

        # Relat√≥rio textual
        st.subheader("üìù Relat√≥rio de An√°lise")
        st.write(f"**Total de documentos analisados:** {len(df)}")

        freq_df = pd.DataFrame(contagem_palavras.most_common(), columns=["Termo", "Frequ√™ncia"])
        st.dataframe(freq_df)

        top_docs = sorted(contagem_por_doc.items(), key=lambda x: x[1], reverse=True)[:5]
        st.write("**Documentos com mais termos relevantes:**")
        st.table(pd.DataFrame(top_docs, columns=["ID do Documento", "Total de Ocorr√™ncias"]))

        # Gr√°fico de barras
        st.subheader("üìä Gr√°fico de Frequ√™ncia de Termos")
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.bar(freq_df["Termo"].head(10), freq_df["Frequ√™ncia"].head(10))
        ax.set_xlabel("Termos de Fashion Law")
        ax.set_ylabel("Frequ√™ncia de Ocorr√™ncia")
        ax.set_title("Top 10 Termos de PI e Contrafa√ß√£o")
        plt.xticks(rotation=45, ha='right')
        st.pyplot(fig)
